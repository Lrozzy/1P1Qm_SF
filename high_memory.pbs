#!/bin/bash

# Use the high-priority development queue w/ #PBS -q devel #PBS -q devel (this doesn't work)
#PBS -l select=1:ncpus=8:mem=3000gb
#PBS -l walltime=48:00:00
#PBS -N SF_job_d9_w6

# oe merges the job's standard output (`stdout`) and standard error (`stderr`)
#PBS -j oe

# output path
#PBS -o /rds/general/user/lr1424/home/1P1Qm_SF/sf_refactor/sf_main_logs/SF_job.dim_cutoff_9_wires_6

cd $PBS_O_WORKDIR

# Load the necessary modules for Conda and CUDA
# echo "Loading modules..."
# module load CUDA/11.8.0

# Activate Conda environment
echo "Initializing Conda for this shell..."
source ~/miniconda3/etc/profile.d/conda.sh

echo "Activating Conda environment: qml-env"
conda activate qml-env

# --- Job Diagnostics ---
echo "--------------------"
echo "Job started on $(hostname) at $(date)"
echo "Job ID: ${PBS_JOBID}"
echo "--------------------"
# echo "Checking GPU status with nvidia-smi:"
# nvidia-smi
# echo "--------------------"
# echo "Checking Python and package versions:"
# which python
# python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__); print('GPU available:', tf.config.list_physical_devices('GPU'))"
# python -c "import strawberryfields as sf; print('Strawberry Fields version:', sf.__version__)"
# echo "--------------------"


# --- Run Your Python Script ---
echo "Starting Python script..."
python /rds/general/user/lr1424/home/1P1Qm_SF/sf_refactor/sf_main.py \
    model.dim_cutoff=9 \
    model.wires=6 \
    model.photon_modes=6 \
    training.epochs=20 \
    training.batch_size=1 \
    data.train_jets=1000 \
    data.val_jets=500 \
    data.test_jets=1000 \
    runtime.run_name="dim9_wires6"
# --- End of Job ---
echo "--------------------"
echo "Job finished at $(date)"