#!/bin/bash

# Use the high-priority development queue w/ #PBS -q devel #PBS -q devel (this doesn't work)
#PBS -l select=1:ncpus=4:mem=1000gb
#PBS -l walltime=24:00:00
#PBS -N SF_job_d10_w10

# oe merges the job's standard output (`stdout`) and standard error (`stderr`)
#PBS -j oe

# output path
#PBS -o /rds/general/user/lr1424/home/1P1Qm_SF/sf_refactor/sf_main_logs/SF_job.dim_cutoff_10_wires_10

cd $PBS_O_WORKDIR

# Load the necessary modules for Conda and CUDA
# echo "Loading modules..."
# module load CUDA/11.8.0

# Activate Conda environment
echo "Initializing Conda for this shell..."
source ~/miniconda3/etc/profile.d/conda.sh

echo "Activating Conda environment: qml-env"
conda activate qml-env

# --- Job Diagnostics ---
echo "--------------------"
echo "Job started on $(hostname) at $(date)"
echo "Job ID: ${PBS_JOBID}"
echo "--------------------"
echo "Checking GPU status with nvidia-smi:"
nvidia-smi
echo "--------------------"
echo "Checking Python and package versions:"
which python
python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__); print('GPU available:', tf.config.list_physical_devices('GPU'))"
# python -c "import strawberryfields as sf; print('Strawberry Fields version:', sf.__version__)"
echo "--------------------"


# --- Run Your Python Script ---
echo "Starting Python script..."
python /rds/general/user/lr1424/home/1P1Qm_SF/sf_refactor/sf_main.py \
    -name "dim10_wires10" \
    --epochs 15 \
    --dim_cutoff 10 \
    --wires 10 \
    --photon_modes 10 \
    --train_jets 1000 \
    --val_jets 500 \
    --test_jets 1000 \
    --batch_size 16 \
# --- End of Job ---
echo "--------------------"
echo "Job finished at $(date)"